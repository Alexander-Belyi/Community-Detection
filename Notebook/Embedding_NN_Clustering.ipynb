{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embedding_NN_Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.set_printoptions(sci_mode=False)"
      ],
      "metadata": {
        "id": "aH23YvKuTW9y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def propEmbed(A, alpha = 0.95):\n",
        "    A = A / A.sum(axis = 1)\n",
        "    n = A.shape[0]\n",
        "    AI = np.linalg.inv(np.eye(n) - A * alpha)\n",
        "    X = (1 - alpha) * AI\n",
        "    return X\n",
        "\n",
        "\n",
        "def modularity_matrix(adj):\n",
        "    w_in = adj.sum(dim=0, keepdim=True)\n",
        "    w_out = adj.sum(dim=1, keepdim=True)\n",
        "    T = w_out.sum()\n",
        "    Q = adj / T - w_out * w_in / T ** 2\n",
        "    return Q\n",
        "\n",
        "def modularity(Q, partition):\n",
        "    return (Q * (partition.reshape(-1,1) == partition.reshape(1,-1))).sum()"
      ],
      "metadata": {
        "id": "S7bPMdVUTkPm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G =  nx.karate_club_graph()\n",
        "#G = nx.les_miserables_graph()\n",
        "A = nx.to_numpy_array(G)\n",
        "X = propEmbed(A, alpha = 0.85)\n",
        "c = KMeans(n_clusters = 4, n_init=100).fit(X.transpose()).labels_\n",
        "adj = torch.FloatTensor(A)\n",
        "Q = modularity_matrix(adj)\n",
        "print(modularity(Q, c).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPDPOtUuTnqH",
        "outputId": "2a8fa329-f4da-4030-d580-7926e26d90c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4197896122932434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout=0.0):\n",
        "        super(GNNLayer, self).__init__()\n",
        "        self.weight1 = nn.Parameter(torch.randn(in_features, out_features)) # 0.5 * torch.eye(in_features, out_features))\n",
        "        self.bias = nn.Parameter(torch.randn(in_features, out_features)) # -0.5 * torch.ones(1, out_features))\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, input):\n",
        "        v1 = torch.mm(input, self.weight1)\n",
        "        output = v1 + self.bias\n",
        "        output = F.dropout(output, p=self.dropout, training=self.training)\n",
        "        return output\n",
        "\n",
        "class GNN_MLP(nn.Module):\n",
        "    def __init__(self, in_features, out_features, diag=False, dropout=0.0):\n",
        "        super(GNN_MLP, self).__init__()\n",
        "        self.gc1 = GNNLayer(in_features, out_features, dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.gc1(x)\n",
        "        x = nn.Softmax(dim=1)(x)\n",
        "        #x = 1.0 + x - x.max(dim=-1, keepdim=True).values\n",
        "        #x = torch.clamp(x, 0, 1)\n",
        "        #x = x / x.sum(dim=-1, keepdim=True) #normalize st sum = 1\n",
        "        return x"
      ],
      "metadata": {
        "id": "fwmyXMYvTcHf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibPTM41DTQ1c",
        "outputId": "b2b136a5-33fc-45c6-fa17-32a223b61d58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 Modularity: -0.01298801 time: 0.1302s\n",
            "Epoch: 1501 Modularity: 0.40277466 time: 0.0005s\n",
            "Epoch: 3001 Modularity: 0.41404045 time: 0.0005s\n",
            "Epoch: 4501 Modularity: 0.41629767 time: 0.0005s\n",
            "Epoch: 6001 Modularity: 0.41696185 time: 0.0005s\n",
            "Epoch: 7501 Modularity: 0.41952392 time: 0.0005s\n",
            "Epoch: 9001 Modularity: 0.41967881 time: 0.0005s\n",
            "Epoch: 10501 Modularity: 0.41973844 time: 0.0005s\n",
            "Epoch: 12001 Modularity: 0.41976547 time: 0.0005s\n",
            "Epoch: 13501 Modularity: 0.41977817 time: 0.0006s\n",
            "Epoch: 15001 Modularity: 0.41978419 time: 0.0005s\n",
            "Epoch: 16501 Modularity: 0.41978702 time: 0.0005s\n",
            "Epoch: 18001 Modularity: 0.41978842 time: 0.0005s\n",
            "Epoch: 19501 Modularity: 0.41978908 time: 0.0005s\n",
            "Epoch: 21001 Modularity: 0.41978940 time: 0.0005s\n",
            "Epoch: 22501 Modularity: 0.41978949 time: 0.0005s\n",
            "Epoch: 24001 Modularity: 0.41978958 time: 0.0005s\n",
            "Epoch: 25501 Modularity: 0.41978961 time: 0.0006s\n",
            "Epoch: 27001 Modularity: 0.41978964 time: 0.0005s\n",
            "Epoch: 28501 Modularity: 0.41978967 time: 0.0005s\n",
            "Epoch: 30000 Modularity: 0.41978967 time: 0.0005s\n",
            "Optimization Finished!\n",
            "Total time elapsed: 16.1861s\n",
            "tensor(-0.4198, grad_fn=<NegBackward0>)\n",
            "tensor([[    0.0000,     1.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     1.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     1.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     1.0000,     0.0000,     0.0000],\n",
            "        [    1.0000,     0.0000,     0.0000,     0.0000],\n",
            "        [    1.0000,     0.0000,     0.0000,     0.0000],\n",
            "        [    1.0000,     0.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     1.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     0.0000,     1.0000,     0.0000],\n",
            "        [    0.0000,     0.0000,     1.0000,     0.0000],\n",
            "        [    1.0000,     0.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     1.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     1.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     1.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     0.0000,     1.0000,     0.0000],\n",
            "        [    0.0000,     0.0000,     1.0000,     0.0000],\n",
            "        [    1.0000,     0.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     1.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     0.0000,     1.0000,     0.0000],\n",
            "        [    0.0000,     1.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     0.0000,     1.0000,     0.0000],\n",
            "        [    0.0000,     1.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     0.0000,     1.0000,     0.0000],\n",
            "        [    0.0000,     0.0000,     0.0000,     1.0000],\n",
            "        [    0.0000,     0.0000,     0.0000,     1.0000],\n",
            "        [    0.0000,     0.0000,     0.0000,     1.0000],\n",
            "        [    0.0000,     0.0000,     1.0000,     0.0000],\n",
            "        [    0.0000,     0.0000,     0.0000,     1.0000],\n",
            "        [    0.0000,     0.0000,     0.0000,     1.0000],\n",
            "        [    0.0000,     0.0000,     1.0000,     0.0000],\n",
            "        [    0.0000,     0.0000,     1.0000,     0.0000],\n",
            "        [    0.0000,     0.0000,     0.0000,     1.0000],\n",
            "        [    0.0000,     0.0000,     1.0000,     0.0000],\n",
            "        [    0.0000,     0.0000,     1.0000,     0.0000]])\n"
          ]
        }
      ],
      "source": [
        "features = torch.FloatTensor(X.transpose())\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "t_total = time.time()\n",
        "n_comm = 4 #features.shape[-1]\n",
        "model = GNN_MLP(features.shape[1], n_comm)\n",
        "lr = 0.002\n",
        "n_epochs = 30000\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "for epoch in range(n_epochs):\n",
        "    t_1run = time.time()\n",
        "    optimizer.zero_grad()\n",
        "    out_embed = model(features)\n",
        "    C = out_embed#[:, :n_comm]\n",
        "    Q1 = torch.mm(C.T, Q)\n",
        "    Q2 = torch.mm(Q1, C)\n",
        "    loss = torch.trace(Q2)\n",
        "    loss = -loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch == 0 or loss < best_loss:\n",
        "        best_loss = loss #- torch.trace(Q)\n",
        "        best_C = C.data\n",
        "        best_embed = out_embed.data\n",
        "        best_epoch = epoch\n",
        "    if n_epochs <= 20 or epoch % (n_epochs//20) == 0 or epoch == n_epochs - 1:\n",
        "        #optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "        print('Epoch: {:04d}'.format(epoch + 1),\n",
        "                'Modularity: {:.8f}'.format(-best_loss.item()),\n",
        "                'time: {:.4f}s'.format(time.time() - t_1run))\n",
        "print(\"Optimization Finished!\")\n",
        "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
        "print(best_loss)\n",
        "print(best_embed)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Whnxlk_EZ0Iy"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}